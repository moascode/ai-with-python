{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2362 1837 1915 ... 3910 3824 2219]\n",
      " [4045 3513  603 ... 1214 4107 1062]\n",
      " [  27 2037  823 ...  750 2578  848]\n",
      " ...\n",
      " [ 940 3908 3303 ... 2323 4304  373]\n",
      " [4663 3500  630 ... 2053 1062  698]\n",
      " [1941 1563 4736 ... 3575 3520  993]]\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5001,size=(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.mean(X, axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "# X_norm = np.divide(np.subtract(X, ave_cols), std_cols)\n",
    "X_norm = (X - ave_cols) / std_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7763568394002505e-18\n",
      "-1.7205940215567233\n",
      "1.7243490802536416\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(X_norm.mean())\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(X_norm.min(axis=0).mean())\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(X_norm.max(axis=0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 2, 4, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[315 681 207 632 219  28 826 929 196 991 483 386 583 193 152 885 726 417\n",
      " 642 212 941 194   3 590 220 727 888 750 925 376 507 298  46 506 830 829\n",
      " 589 660 179 407 377 690   6 968 796 900 674  77 956 109 872 495 137 254\n",
      " 271 512 160 671 205 869 631 950 354 577  97 153 774 222 200 474 703 620\n",
      " 164 519 244 522 518 145 951 517  76 997 525 560 534 848 299 664 209 366\n",
      " 921  43 877 839 942 986 308 965 776 567 960   8 437 102 378 262 622 649\n",
      " 804 424 273 239 795 600 613  71 427 661 389 104 766 533 390 702 142 459\n",
      " 411 656 579 654 730   1 928 635 348 725 304 568 114 833 249 707 867  53\n",
      " 392 123 870   9 255 587 930  80 161 970 768 601 763 990 187 503 692 677\n",
      " 218 863 288 162 541 139 150 372 391 321 505 585 410 945 753 388 240 994\n",
      " 565  78 792 186  48 771  51 791 973 343 107 938 612 545 454 606 536 432\n",
      "  37 472 367 855 745 967 891 352  73 923 591 481  21 154 769 623 480 446\n",
      " 685 257 329 538 401 455 651 919 413 866 772 854 537 878 203  91 716 547\n",
      " 181 911 540  22 731 604 793 470 434 592  27 508 307 277 272 688 993 980\n",
      " 349 238 582 542 865 879 611 165 628 302 543  89 405 824 451 647 559 955\n",
      " 173 510 339 743 998 904  67 838 910 340 167 341 775 561 296 396 444 283\n",
      " 223 825 761 504 588 580 442 987 926 280 460 252 141 814 719 345 667  94\n",
      " 253 652 330 490 554 112 213 464 821 487 131 516 790 828 820 881 781 316\n",
      " 100 608 270 574  41 913 342 954 747 246 387 513 786 566 148 636 922 320\n",
      "  50 936 897 498 819 291 149 295 700 812 327 228 665   5 729 995 319 871\n",
      "  18 917 233 787 892 492 400  84 858 815 640 402  68 117 303 127 155 597\n",
      " 893 676 509 279 336 138 648 231 265 722 546 230  13 412 466  65 794 428\n",
      " 105 294 373 243 704 723  47 873 887 166 693 496 502 807 399 539 535 364\n",
      "   4 842 128 404 752 851 811 467  64 663 666 318  60 324  90 488 119  79\n",
      " 408  49 721 896 395 657 136 264 306 977 832 621 709  40 433 853 133 691\n",
      " 430  44 759 979 754 311 901 713 961 278 267 523 981  70 237 285 777 734\n",
      " 337  72 653 135 441  83 129 834 465 553 317 852 326 864 531 586  99 598\n",
      " 578 242 199 701 605 310 526 607 883 184 673 827  88 614 862  38 933 351\n",
      "  96 762 785  32 915 177  58 251 823 985 381 634 478 528 325 556 379  29\n",
      " 197 475 250 931 744 418 245 735 943 966 215 420 284  34 159 780 937 297\n",
      " 176 847 520 468 976 182 266 907 549 462 767 529 146 695 983 118 882 190\n",
      " 801 134 932 375 837 361 638 658 679  61 224 443 369 258 286 172 944 905\n",
      "   7 217 712 758 125 292 760  86  31 959 662  20 544 334 132 783 952 964\n",
      " 859 918 682 706 948 696 202 788 229 720 558 282 431 599 259 564 191 770\n",
      " 356 355 889 151 393 627 473 143 868 260 281 996 972 844 268 227 439 797\n",
      " 305   0 740 958 248 301 440 463 953 569 416 115  62 584 486 256 183 241\n",
      " 669 739 358 808  95 171 274 374 275 637 817 263 501 425 530 914 659  74\n",
      " 204 646 521 594 717 469 124 849 216 331 383 773  24 924 751 902 708 527\n",
      " 655 738 705 269 609 633 895 733 920 875 711 710 347 312 552 724 846 313\n",
      " 168 672  92 477 276 363 414 697 360 144 344  45  33 449 755 880 201 175\n",
      " 934 935 836 999 415  93 908 809 603 550 668 192 789 397 448 309 226 641\n",
      " 290 551 110 563 458  11 850 235  26  81 419 890 429 169 803 581 715 335\n",
      "  36 949 969 680 438 368 816 947 963 971 122 409 835 524 359 225 406 898\n",
      " 978 625 810 818 686 300 445 593 247 435 732 800 484 447 120 884 576 856\n",
      " 489 957 840 461 322 619 618 912 328 157 571  30 779 532  87 684 841 845\n",
      " 802 749 548 974 195 757 456 629 570 595 670  66 426 737 843 610 876 382\n",
      " 287  54 208 857 728  69 602 982 756  98 894 831 916 989 500 616 822 860\n",
      " 211 479 861 742 746 189 765 198 422 371 357 234 927 491 452 126 630 940\n",
      " 736  12  75 497 992 899 370 403 689  19 485 158 384 650 101  63 699 909\n",
      " 805 457 562 471  10 174 615  15 436 493 394 748 778 365 170 380 323 221\n",
      " 557 338  55 130 482 332 261 596 350 678 206 906 140 156 806 784 178 764\n",
      " 714  42  52 346 232 385 675 353  39 494 476 698 694 741 514 188 626 624\n",
      "  56  17 236 103 116 813 639 450   2 314 121 645 108 874  16 113 111 210\n",
      " 617 421 643 799 106  85 185 453 573 718 398 289 687  14 988  35  82 984\n",
      " 362  59 333 903 572 644 939 555 499 147 214 511  23 683 886 798 782 423\n",
      " 575 163 515 946 962  57 293  25 975 180]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "\n",
    "# Create a Training Set\n",
    "sixty = int (row_indices.size * 0.6)\n",
    "X_train = X_norm[row_indices[:sixty], :]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "eighty = int (row_indices.size * 0.8)\n",
    "X_crossVal = X_norm[row_indices[sixty:eighty], :]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[row_indices[eighty:], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
